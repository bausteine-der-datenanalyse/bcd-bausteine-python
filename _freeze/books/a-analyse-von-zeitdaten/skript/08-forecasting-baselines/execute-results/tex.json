{
  "hash": "69f23a1a1b1516d6896f37d1f2104cd0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"8 Forecasting-Baselines & Bewertung\"\n---\n\n# 8 Forecasting-Baselines & Bewertung\n\nBevor komplexe Modelle eingesetzt werden, sollten immer einfache\n**Baseline-Modelle** definiert werden.\n\nBaselines beantworten die Frage:\n\n> Ist mein Modell wirklich besser als eine einfache, nachvollziehbare Strategie?\n\n---\n\n::: {.callout-note title=\"Merke\"}\nEin komplexes Modell ist nur dann sinnvoll,\nwenn es robuste Baselines klar übertrifft.\n:::\n\n---\n\n## 8.1 Beispielzeitreihe\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nrng = np.random.default_rng(123)\n\nt = pd.date_range(\"2025-01-01\", periods=24*14, freq=\"H\")\ntrend = np.linspace(0, 2, len(t))\nseason = 0.9 * np.sin(2*np.pi*(t.hour)/24)\nnoise = 0.3 * rng.normal(size=len(t))\n\ns = pd.Series(20 + trend + season + noise, index=t, name=\"signal\")\n\ns.plot(title=\"Zeitreihe für Forecasting\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/p_/ks3trxjx0jd839_g4g0vm4nc0000gn/T/ipykernel_21452/1656542722.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  t = pd.date_range(\"2025-01-01\", periods=24*14, freq=\"H\")\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](08-forecasting-baselines_files/figure-pdf/cell-2-output-2.png){fig-pos='H'}\n:::\n:::\n\n\n---\n\n## 8.2 Train-Test-Split\n\nWir verwenden 80% der Daten für Training und 20% für Test.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nsplit = int(len(s) * 0.8)\n\ntrain = s.iloc[:split]\ntest = s.iloc[split:]\n\ntrain.index.min(), train.index.max(), test.index.min(), test.index.max()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n(Timestamp('2025-01-01 00:00:00'),\n Timestamp('2025-01-12 03:00:00'),\n Timestamp('2025-01-12 04:00:00'),\n Timestamp('2025-01-14 23:00:00'))\n```\n:::\n:::\n\n\n---\n\n## 8.3 Naive Forecast\n\nNächster Wert = letzter beobachteter Wert.\n\n::: {.panel-tabset}\n\n## Pandas\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nnaive = test.copy()\nnaive[:] = train.iloc[-1]\n```\n:::\n\n\n## NumPy\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ny = s.to_numpy()\ntrain_np = y[:split]\ntest_np = y[split:]\n\nnaive_np = np.full_like(test_np, train_np[-1])\n```\n:::\n\n\n:::\n\n---\n\n## 8.4 Seasonal Naive (24 Stunden)\n\nNächster Wert = Wert von vor 24 Stunden.\n\n::: {.panel-tabset}\n\n## Pandas\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nseasonal_naive = s.shift(24).iloc[split:]\n```\n:::\n\n\n## NumPy\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nseasonal_naive_np = y[split-24:-24]\n```\n:::\n\n\n:::\n\n---\n\n## 8.5 Moving Average Baseline\n\nForecast = Mittelwert der letzten 24 Stunden.\n\n::: {.panel-tabset}\n\n## Pandas\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nma_value = train.iloc[-24:].mean()\nma_forecast = test.copy()\nma_forecast[:] = ma_value\n```\n:::\n\n\n## NumPy\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nma_value_np = np.mean(train_np[-24:])\nma_forecast_np = np.full_like(test_np, ma_value_np)\n```\n:::\n\n\n:::\n\n---\n\n## 8.6 Vergleich visualisieren\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nplt.figure()\ntrain.plot(label=\"Train\")\ntest.plot(label=\"Test\")\nnaive.plot(label=\"Naive\")\nseasonal_naive.plot(label=\"Seasonal Naive\")\nma_forecast.plot(label=\"MA(24)\")\nplt.legend()\nplt.title(\"Forecast Baselines\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](08-forecasting-baselines_files/figure-pdf/cell-10-output-1.png){fig-pos='H'}\n:::\n:::\n\n\n---\n\n## 8.7 Fehlermaße\n\nWir verwenden den Mean Absolute Error (MAE):\n\n\\[\nMAE = \\frac{1}{n} \\sum |y_{true} - y_{pred}|\n\\]\n\n::: {.panel-tabset}\n\n## Pandas\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef mae(y_true, y_pred):\n    return np.mean(np.abs(y_true - y_pred))\n\nprint(\"MAE Naive:\", mae(test, naive))\nprint(\"MAE Seasonal Naive:\", mae(test, seasonal_naive))\nprint(\"MAE MA(24):\", mae(test, ma_forecast))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE Naive: 0.6298837368696829\nMAE Seasonal Naive: 0.3320412574311427\nMAE MA(24): 0.6228787570177815\n```\n:::\n:::\n\n\n## NumPy\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndef mae_np(y_true, y_pred):\n    return np.mean(np.abs(y_true - y_pred))\n\nprint(\"MAE Naive:\", mae_np(test_np, naive_np))\nprint(\"MAE Seasonal:\", mae_np(test_np, seasonal_naive_np))\nprint(\"MAE MA(24):\", mae_np(test_np, ma_forecast_np))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMAE Naive: 0.6298837368696829\nMAE Seasonal: 0.3320412574311427\nMAE MA(24): 0.6228787570177815\n```\n:::\n:::\n\n\n:::\n\n---\n\n## 8.8 Interpretation\n\nTypische Beobachtungen:\n\n- Bei starker Saison gewinnt häufig Seasonal Naive.\n- Bei schwachem Muster ist Naive oft überraschend stark.\n- Moving Average glättet, reagiert aber träge auf Trendänderungen.\n\n---\n\n::: {.callout-tip title=\"Methodischer Hinweis\"}\nBaseline-Vergleich ist keine Formalität,\nsondern eine Qualitätskontrolle.\n:::\n\n---\n\n## 8.9 Mini-Aufgaben\n\n1. Erhöhen Sie die Stärke der Saison.  \n   - Welche Baseline gewinnt?\n\n2. Entfernen Sie die Saison vollständig.  \n   - Welche Baseline wird besser?\n\n3. Fügen Sie einen starken Trend hinzu.  \n   - Wie reagieren die Modelle?\n\n",
    "supporting": [
      "08-forecasting-baselines_files/figure-pdf"
    ],
    "filters": []
  }
}